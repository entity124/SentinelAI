{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 933,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010726736390453205,
      "grad_norm": 2.089604616165161,
      "learning_rate": 0.00019935691318327976,
      "loss": 0.9558,
      "step": 10
    },
    {
      "epoch": 0.02145347278090641,
      "grad_norm": 1.8485296964645386,
      "learning_rate": 0.00019864237227581278,
      "loss": 0.4396,
      "step": 20
    },
    {
      "epoch": 0.032180209171359615,
      "grad_norm": 0.8241973519325256,
      "learning_rate": 0.00019792783136834586,
      "loss": 0.4298,
      "step": 30
    },
    {
      "epoch": 0.04290694556181282,
      "grad_norm": 0.6148632764816284,
      "learning_rate": 0.00019721329046087888,
      "loss": 0.4276,
      "step": 40
    },
    {
      "epoch": 0.053633681952266025,
      "grad_norm": 0.5621463656425476,
      "learning_rate": 0.00019649874955341193,
      "loss": 0.3999,
      "step": 50
    },
    {
      "epoch": 0.06436041834271923,
      "grad_norm": 0.8952690362930298,
      "learning_rate": 0.000195784208645945,
      "loss": 0.4039,
      "step": 60
    },
    {
      "epoch": 0.07508715473317243,
      "grad_norm": 1.3261749744415283,
      "learning_rate": 0.00019506966773847803,
      "loss": 0.3733,
      "step": 70
    },
    {
      "epoch": 0.08581389112362564,
      "grad_norm": 0.6024514436721802,
      "learning_rate": 0.00019435512683101109,
      "loss": 0.3722,
      "step": 80
    },
    {
      "epoch": 0.09654062751407884,
      "grad_norm": 0.6391403675079346,
      "learning_rate": 0.00019364058592354414,
      "loss": 0.3593,
      "step": 90
    },
    {
      "epoch": 0.10726736390453205,
      "grad_norm": 0.9072715044021606,
      "learning_rate": 0.00019292604501607719,
      "loss": 0.383,
      "step": 100
    },
    {
      "epoch": 0.11799410029498525,
      "grad_norm": 0.6153451204299927,
      "learning_rate": 0.0001922115041086102,
      "loss": 0.3837,
      "step": 110
    },
    {
      "epoch": 0.12872083668543846,
      "grad_norm": 0.7335195541381836,
      "learning_rate": 0.00019149696320114329,
      "loss": 0.3666,
      "step": 120
    },
    {
      "epoch": 0.13944757307589167,
      "grad_norm": 0.857377290725708,
      "learning_rate": 0.00019078242229367634,
      "loss": 0.3738,
      "step": 130
    },
    {
      "epoch": 0.15017430946634486,
      "grad_norm": 0.9024446606636047,
      "learning_rate": 0.00019006788138620936,
      "loss": 0.3721,
      "step": 140
    },
    {
      "epoch": 0.16090104585679807,
      "grad_norm": 0.6107615828514099,
      "learning_rate": 0.00018935334047874244,
      "loss": 0.3435,
      "step": 150
    },
    {
      "epoch": 0.17162778224725128,
      "grad_norm": 0.8621557950973511,
      "learning_rate": 0.00018863879957127546,
      "loss": 0.3772,
      "step": 160
    },
    {
      "epoch": 0.18235451863770447,
      "grad_norm": 0.5189794301986694,
      "learning_rate": 0.0001879242586638085,
      "loss": 0.3722,
      "step": 170
    },
    {
      "epoch": 0.19308125502815768,
      "grad_norm": 0.5938416123390198,
      "learning_rate": 0.00018720971775634156,
      "loss": 0.3113,
      "step": 180
    },
    {
      "epoch": 0.2038079914186109,
      "grad_norm": 0.5406862497329712,
      "learning_rate": 0.0001864951768488746,
      "loss": 0.3241,
      "step": 190
    },
    {
      "epoch": 0.2145347278090641,
      "grad_norm": 0.4746014177799225,
      "learning_rate": 0.00018578063594140763,
      "loss": 0.3746,
      "step": 200
    },
    {
      "epoch": 0.2252614641995173,
      "grad_norm": 0.652690052986145,
      "learning_rate": 0.0001850660950339407,
      "loss": 0.3233,
      "step": 210
    },
    {
      "epoch": 0.2359882005899705,
      "grad_norm": 0.4155222177505493,
      "learning_rate": 0.00018435155412647376,
      "loss": 0.3366,
      "step": 220
    },
    {
      "epoch": 0.2467149369804237,
      "grad_norm": 0.5890516638755798,
      "learning_rate": 0.00018363701321900678,
      "loss": 0.333,
      "step": 230
    },
    {
      "epoch": 0.2574416733708769,
      "grad_norm": 0.6159314513206482,
      "learning_rate": 0.00018292247231153986,
      "loss": 0.3278,
      "step": 240
    },
    {
      "epoch": 0.2681684097613301,
      "grad_norm": 0.48545676469802856,
      "learning_rate": 0.00018220793140407289,
      "loss": 0.335,
      "step": 250
    },
    {
      "epoch": 0.27889514615178335,
      "grad_norm": 0.4906125068664551,
      "learning_rate": 0.00018149339049660594,
      "loss": 0.329,
      "step": 260
    },
    {
      "epoch": 0.28962188254223653,
      "grad_norm": 0.573398232460022,
      "learning_rate": 0.00018077884958913899,
      "loss": 0.3162,
      "step": 270
    },
    {
      "epoch": 0.3003486189326897,
      "grad_norm": 0.47409161925315857,
      "learning_rate": 0.00018006430868167204,
      "loss": 0.3365,
      "step": 280
    },
    {
      "epoch": 0.31107535532314295,
      "grad_norm": 0.8601828813552856,
      "learning_rate": 0.0001793497677742051,
      "loss": 0.324,
      "step": 290
    },
    {
      "epoch": 0.32180209171359614,
      "grad_norm": 0.7798998951911926,
      "learning_rate": 0.00017863522686673814,
      "loss": 0.3397,
      "step": 300
    },
    {
      "epoch": 0.3325288281040493,
      "grad_norm": 0.6310964226722717,
      "learning_rate": 0.0001779206859592712,
      "loss": 0.2986,
      "step": 310
    },
    {
      "epoch": 0.34325556449450256,
      "grad_norm": 0.7329403162002563,
      "learning_rate": 0.0001772061450518042,
      "loss": 0.3331,
      "step": 320
    },
    {
      "epoch": 0.35398230088495575,
      "grad_norm": 0.42413192987442017,
      "learning_rate": 0.0001764916041443373,
      "loss": 0.3249,
      "step": 330
    },
    {
      "epoch": 0.36470903727540893,
      "grad_norm": 0.5837903618812561,
      "learning_rate": 0.0001757770632368703,
      "loss": 0.3323,
      "step": 340
    },
    {
      "epoch": 0.37543577366586217,
      "grad_norm": 0.6535207033157349,
      "learning_rate": 0.00017506252232940336,
      "loss": 0.3519,
      "step": 350
    },
    {
      "epoch": 0.38616251005631536,
      "grad_norm": 0.5044068098068237,
      "learning_rate": 0.0001743479814219364,
      "loss": 0.3193,
      "step": 360
    },
    {
      "epoch": 0.3968892464467686,
      "grad_norm": 0.42790254950523376,
      "learning_rate": 0.00017363344051446946,
      "loss": 0.3411,
      "step": 370
    },
    {
      "epoch": 0.4076159828372218,
      "grad_norm": 0.7333489656448364,
      "learning_rate": 0.0001729188996070025,
      "loss": 0.3421,
      "step": 380
    },
    {
      "epoch": 0.41834271922767496,
      "grad_norm": 0.701528787612915,
      "learning_rate": 0.00017220435869953556,
      "loss": 0.3292,
      "step": 390
    },
    {
      "epoch": 0.4290694556181282,
      "grad_norm": 0.5943056344985962,
      "learning_rate": 0.0001714898177920686,
      "loss": 0.3059,
      "step": 400
    },
    {
      "epoch": 0.4397961920085814,
      "grad_norm": 0.5709913969039917,
      "learning_rate": 0.00017077527688460164,
      "loss": 0.3164,
      "step": 410
    },
    {
      "epoch": 0.4505229283990346,
      "grad_norm": 0.5902494192123413,
      "learning_rate": 0.0001700607359771347,
      "loss": 0.3573,
      "step": 420
    },
    {
      "epoch": 0.4612496647894878,
      "grad_norm": 0.6690712571144104,
      "learning_rate": 0.00016934619506966776,
      "loss": 0.315,
      "step": 430
    },
    {
      "epoch": 0.471976401179941,
      "grad_norm": 1.3926866054534912,
      "learning_rate": 0.00016863165416220079,
      "loss": 0.305,
      "step": 440
    },
    {
      "epoch": 0.4827031375703942,
      "grad_norm": 0.39413824677467346,
      "learning_rate": 0.00016791711325473384,
      "loss": 0.3271,
      "step": 450
    },
    {
      "epoch": 0.4934298739608474,
      "grad_norm": 0.5825746059417725,
      "learning_rate": 0.0001672025723472669,
      "loss": 0.3488,
      "step": 460
    },
    {
      "epoch": 0.5041566103513007,
      "grad_norm": 0.5792669653892517,
      "learning_rate": 0.00016648803143979994,
      "loss": 0.2854,
      "step": 470
    },
    {
      "epoch": 0.5148833467417538,
      "grad_norm": 0.6634381413459778,
      "learning_rate": 0.000165773490532333,
      "loss": 0.3231,
      "step": 480
    },
    {
      "epoch": 0.525610083132207,
      "grad_norm": 0.4661059081554413,
      "learning_rate": 0.00016505894962486604,
      "loss": 0.2894,
      "step": 490
    },
    {
      "epoch": 0.5363368195226602,
      "grad_norm": 0.6080760955810547,
      "learning_rate": 0.0001643444087173991,
      "loss": 0.3073,
      "step": 500
    },
    {
      "epoch": 0.5470635559131134,
      "grad_norm": 0.6487169861793518,
      "learning_rate": 0.0001636298678099321,
      "loss": 0.3425,
      "step": 510
    },
    {
      "epoch": 0.5577902923035667,
      "grad_norm": 0.8207961916923523,
      "learning_rate": 0.0001629153269024652,
      "loss": 0.3435,
      "step": 520
    },
    {
      "epoch": 0.5685170286940199,
      "grad_norm": 0.5311927199363708,
      "learning_rate": 0.0001622007859949982,
      "loss": 0.3123,
      "step": 530
    },
    {
      "epoch": 0.5792437650844731,
      "grad_norm": 0.5726441740989685,
      "learning_rate": 0.00016148624508753126,
      "loss": 0.3166,
      "step": 540
    },
    {
      "epoch": 0.5899705014749262,
      "grad_norm": 2.0389695167541504,
      "learning_rate": 0.0001607717041800643,
      "loss": 0.2929,
      "step": 550
    },
    {
      "epoch": 0.6006972378653794,
      "grad_norm": 0.6408104300498962,
      "learning_rate": 0.00016005716327259736,
      "loss": 0.3247,
      "step": 560
    },
    {
      "epoch": 0.6114239742558326,
      "grad_norm": 0.6224600672721863,
      "learning_rate": 0.0001593426223651304,
      "loss": 0.3226,
      "step": 570
    },
    {
      "epoch": 0.6221507106462859,
      "grad_norm": 0.696281909942627,
      "learning_rate": 0.00015862808145766346,
      "loss": 0.3162,
      "step": 580
    },
    {
      "epoch": 0.6328774470367391,
      "grad_norm": 0.702283501625061,
      "learning_rate": 0.0001579135405501965,
      "loss": 0.3137,
      "step": 590
    },
    {
      "epoch": 0.6436041834271923,
      "grad_norm": 0.7402451038360596,
      "learning_rate": 0.00015719899964272954,
      "loss": 0.3146,
      "step": 600
    },
    {
      "epoch": 0.6543309198176455,
      "grad_norm": 0.5271433591842651,
      "learning_rate": 0.00015648445873526261,
      "loss": 0.3073,
      "step": 610
    },
    {
      "epoch": 0.6650576562080986,
      "grad_norm": 0.5023890137672424,
      "learning_rate": 0.00015576991782779564,
      "loss": 0.2977,
      "step": 620
    },
    {
      "epoch": 0.6757843925985519,
      "grad_norm": 0.4529865086078644,
      "learning_rate": 0.0001550553769203287,
      "loss": 0.3084,
      "step": 630
    },
    {
      "epoch": 0.6865111289890051,
      "grad_norm": 0.4640941321849823,
      "learning_rate": 0.00015434083601286174,
      "loss": 0.3005,
      "step": 640
    },
    {
      "epoch": 0.6972378653794583,
      "grad_norm": 0.4954255223274231,
      "learning_rate": 0.0001536262951053948,
      "loss": 0.2966,
      "step": 650
    },
    {
      "epoch": 0.7079646017699115,
      "grad_norm": 0.4603368937969208,
      "learning_rate": 0.00015291175419792784,
      "loss": 0.3336,
      "step": 660
    },
    {
      "epoch": 0.7186913381603647,
      "grad_norm": 0.388258695602417,
      "learning_rate": 0.0001521972132904609,
      "loss": 0.3143,
      "step": 670
    },
    {
      "epoch": 0.7294180745508179,
      "grad_norm": 0.5367987751960754,
      "learning_rate": 0.00015148267238299394,
      "loss": 0.2915,
      "step": 680
    },
    {
      "epoch": 0.7401448109412712,
      "grad_norm": 0.5187452435493469,
      "learning_rate": 0.00015076813147552696,
      "loss": 0.3154,
      "step": 690
    },
    {
      "epoch": 0.7508715473317243,
      "grad_norm": 0.5130612254142761,
      "learning_rate": 0.00015005359056806004,
      "loss": 0.3124,
      "step": 700
    },
    {
      "epoch": 0.7615982837221775,
      "grad_norm": 1.182473063468933,
      "learning_rate": 0.00014933904966059306,
      "loss": 0.2865,
      "step": 710
    },
    {
      "epoch": 0.7723250201126307,
      "grad_norm": 0.5889764428138733,
      "learning_rate": 0.0001486245087531261,
      "loss": 0.2756,
      "step": 720
    },
    {
      "epoch": 0.7830517565030839,
      "grad_norm": 0.40656742453575134,
      "learning_rate": 0.0001479099678456592,
      "loss": 0.3182,
      "step": 730
    },
    {
      "epoch": 0.7937784928935372,
      "grad_norm": 0.5578835606575012,
      "learning_rate": 0.0001471954269381922,
      "loss": 0.2832,
      "step": 740
    },
    {
      "epoch": 0.8045052292839904,
      "grad_norm": 0.4362930953502655,
      "learning_rate": 0.00014648088603072526,
      "loss": 0.31,
      "step": 750
    },
    {
      "epoch": 0.8152319656744436,
      "grad_norm": 0.5347860455513,
      "learning_rate": 0.00014576634512325831,
      "loss": 0.3331,
      "step": 760
    },
    {
      "epoch": 0.8259587020648967,
      "grad_norm": 0.5041791200637817,
      "learning_rate": 0.00014505180421579136,
      "loss": 0.2848,
      "step": 770
    },
    {
      "epoch": 0.8366854384553499,
      "grad_norm": 0.4602130055427551,
      "learning_rate": 0.0001443372633083244,
      "loss": 0.3183,
      "step": 780
    },
    {
      "epoch": 0.8474121748458031,
      "grad_norm": 0.48564380407333374,
      "learning_rate": 0.00014362272240085746,
      "loss": 0.3196,
      "step": 790
    },
    {
      "epoch": 0.8581389112362564,
      "grad_norm": 0.6362956762313843,
      "learning_rate": 0.00014290818149339051,
      "loss": 0.2982,
      "step": 800
    },
    {
      "epoch": 0.8688656476267096,
      "grad_norm": 0.5687089562416077,
      "learning_rate": 0.00014219364058592354,
      "loss": 0.3117,
      "step": 810
    },
    {
      "epoch": 0.8795923840171628,
      "grad_norm": 0.42851507663726807,
      "learning_rate": 0.00014147909967845662,
      "loss": 0.3273,
      "step": 820
    },
    {
      "epoch": 0.890319120407616,
      "grad_norm": 0.5189082622528076,
      "learning_rate": 0.00014076455877098964,
      "loss": 0.2896,
      "step": 830
    },
    {
      "epoch": 0.9010458567980691,
      "grad_norm": 0.43528884649276733,
      "learning_rate": 0.0001400500178635227,
      "loss": 0.3027,
      "step": 840
    },
    {
      "epoch": 0.9117725931885224,
      "grad_norm": 0.4255653917789459,
      "learning_rate": 0.00013933547695605574,
      "loss": 0.2993,
      "step": 850
    },
    {
      "epoch": 0.9224993295789756,
      "grad_norm": 0.5968857407569885,
      "learning_rate": 0.0001386209360485888,
      "loss": 0.285,
      "step": 860
    },
    {
      "epoch": 0.9332260659694288,
      "grad_norm": 0.45269203186035156,
      "learning_rate": 0.00013790639514112184,
      "loss": 0.2957,
      "step": 870
    },
    {
      "epoch": 0.943952802359882,
      "grad_norm": 0.4291684031486511,
      "learning_rate": 0.0001371918542336549,
      "loss": 0.3006,
      "step": 880
    },
    {
      "epoch": 0.9546795387503352,
      "grad_norm": 0.40244296193122864,
      "learning_rate": 0.00013647731332618794,
      "loss": 0.2921,
      "step": 890
    },
    {
      "epoch": 0.9654062751407884,
      "grad_norm": 0.44371533393859863,
      "learning_rate": 0.00013576277241872096,
      "loss": 0.3315,
      "step": 900
    },
    {
      "epoch": 0.9761330115312417,
      "grad_norm": 0.6033384799957275,
      "learning_rate": 0.00013504823151125404,
      "loss": 0.2911,
      "step": 910
    },
    {
      "epoch": 0.9868597479216948,
      "grad_norm": 0.4444904923439026,
      "learning_rate": 0.00013433369060378706,
      "loss": 0.3176,
      "step": 920
    },
    {
      "epoch": 0.997586484312148,
      "grad_norm": 0.5050438046455383,
      "learning_rate": 0.00013361914969632011,
      "loss": 0.287,
      "step": 930
    }
  ],
  "logging_steps": 10,
  "max_steps": 2799,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.693939079879066e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
